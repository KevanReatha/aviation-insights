{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04786f36",
   "metadata": {},
   "source": [
    "# 0) Imports & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a881b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hist_t1  -> International_airline_activity_Table1_2009toCurrent_0525_Data - Sheet1.csv | exists=True\n",
      "t1_may   -> International_airline_activity_0525_Table1.csv | exists=True\n",
      "t2_may   -> International_airline_activity_0525_Table2.csv | exists=True\n",
      "t3_may   -> International_airline_activity_0525_Table3.csv | exists=True\n",
      "t4_may   -> International_airline_activity_0525_Table4.csv | exists=True\n",
      "t5_may   -> International_airline_activity_0525_Table5.csv | exists=True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "\n",
    "BASE = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "RAW  = BASE / \"data\" / \"raw\"\n",
    "CLEAN = BASE / \"data\" / \"clean\"\n",
    "CLEAN.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FILES = {\n",
    "    \"hist_t1\": RAW / \"International_airline_activity_Table1_2009toCurrent_0525_Data - Sheet1.csv\",\n",
    "    \"t1_may\":  RAW / \"International_airline_activity_0525_Table1.csv\",\n",
    "    \"t2_may\":  RAW / \"International_airline_activity_0525_Table2.csv\",\n",
    "    \"t3_may\":  RAW / \"International_airline_activity_0525_Table3.csv\",\n",
    "    \"t4_may\":  RAW / \"International_airline_activity_0525_Table4.csv\",\n",
    "    \"t5_may\":  RAW / \"International_airline_activity_0525_Table5.csv\",\n",
    "}\n",
    "\n",
    "for k,p in FILES.items():\n",
    "    print(f\"{k:8s} -> {p.name} | exists={p.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1315577f",
   "metadata": {},
   "source": [
    "# 1) Helpers: parsing & cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bae799e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NULL_TOKENS = {\"..\", \"-\", \"\", None, \"nan\", \"NaN\", \"None\"}\n",
    "\n",
    "def to_number(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Coerce strings like '1,234' or '1 234' or '..' to floats. Returns float with NaN on bad.\"\"\"\n",
    "    x = s.astype(str).str.strip()\n",
    "    x = x.where(~x.isin(NULL_TOKENS), None)\n",
    "    x = x.str.replace(\",\", \"\", regex=False).str.replace(\" \", \"\", regex=False)\n",
    "    return pd.to_numeric(x, errors=\"coerce\")\n",
    "\n",
    "def to_percent_decimal(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Converts '12.3%' -> 0.123, '12,3' -> 0.123 if suffixed with %, else 12.3 -> 12.3 (assumed already decimal).\n",
    "       If the column is known to be percentage values without %, divide by 100 yourself before calling this.\"\"\"\n",
    "    x = s.astype(str).str.strip()\n",
    "    x = x.where(~x.isin(NULL_TOKENS), None)\n",
    "    # Replace comma decimal -> dot\n",
    "    x = x.str.replace(\",\", \".\", regex=False)\n",
    "    pct_mask = x.str.endswith(\"%\", na=False)\n",
    "    x = x.str.rstrip(\"%\")\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    x[pct_mask] = x[pct_mask] / 100.0\n",
    "    return x\n",
    "\n",
    "def clean_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = (\n",
    "        df.columns.astype(str)\n",
    "          .str.strip()\n",
    "          .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "          .str.replace(r\"[()]\", \"\", regex=True)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b502001",
   "metadata": {},
   "source": [
    "# 2) Clean HISTORICAL (Table 1, 2009→current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e94c568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_table1_hist(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = clean_cols(df_raw)\n",
    "\n",
    "    # Expected columns (case-insensitive): Month, Year, Scheduled Operator, Country to/from, Passengers In/Out, Freight In/Out, Mail In/Out\n",
    "    ren = {\n",
    "        \"Scheduled_Operator\": \"Airline_Name\",\n",
    "        \"Country_to/from\": \"Country\",\n",
    "        \"Passengers_In\": \"Passengers_In\",\n",
    "        \"Passengers_Out\": \"Passengers_Out\",\n",
    "        \"Freight_In\": \"Freight_In\",\n",
    "        \"Freight_Out\": \"Freight_Out\",\n",
    "        \"Mail_In\": \"Mail_In\",\n",
    "        \"Mail_Out\": \"Mail_Out\",\n",
    "        \"Year\": \"Year\",\n",
    "        \"Month\": \"Month\"\n",
    "    }\n",
    "    # Ensure the keys exist even if case differs\n",
    "    rename_map = {c: ren.get(c, c) for c in df.columns}\n",
    "    df = df.rename(columns=rename_map)\n",
    "\n",
    "    # Normalise month text like 'Jan-09'\n",
    "    # Two cases: Month column exists OR the month text is in first column named 'Month'\n",
    "    # We derive numeric month from the Month string if needed\n",
    "    if \"Month\" in df:\n",
    "        # Month may look like 'Jan-09' or 'May-25' etc. Let's parse:\n",
    "        mtxt = df[\"Month\"].astype(str).str.strip()\n",
    "        # Extract month name (first 3 letters) and year (last 2 if present)\n",
    "        # We already have a numeric Year column, so we rely on Year for year.\n",
    "        month_map = {\n",
    "            \"jan\":1,\"feb\":2,\"mar\":3,\"apr\":4,\"may\":5,\"jun\":6,\n",
    "            \"jul\":7,\"aug\":8,\"sep\":9,\"oct\":10,\"nov\":11,\"dec\":12\n",
    "        }\n",
    "        df[\"Month_num\"] = mtxt.str[:3].str.lower().map(month_map)\n",
    "    else:\n",
    "        df[\"Month_num\"] = None\n",
    "\n",
    "    # Numbers\n",
    "    for c in [\"Passengers_In\",\"Passengers_Out\",\"Freight_In\",\"Freight_Out\",\"Mail_In\",\"Mail_Out\"]:\n",
    "        if c in df: df[c] = to_number(df[c])\n",
    "\n",
    "    # Melt inbound/outbound\n",
    "    cols_keep = [\"Year\",\"Month_num\",\"Airline_Name\",\"Country\"]\n",
    "    for c in cols_keep:\n",
    "        if c not in df: df[c] = None\n",
    "\n",
    "    inbound = df[cols_keep + [\"Passengers_In\",\"Freight_In\",\"Mail_In\"]].copy()\n",
    "    inbound[\"Direction\"] = \"Inbound\"\n",
    "    inbound = inbound.rename(columns={\n",
    "        \"Passengers_In\":\"Passengers\",\n",
    "        \"Freight_In\":\"Freight_tonnes\",\n",
    "        \"Mail_In\":\"Mail_tonnes\",\n",
    "        \"Month_num\":\"Month\"\n",
    "    })\n",
    "\n",
    "    outbound = df[cols_keep + [\"Passengers_Out\",\"Freight_Out\",\"Mail_Out\"]].copy()\n",
    "    outbound[\"Direction\"] = \"Outbound\"\n",
    "    outbound = outbound.rename(columns={\n",
    "        \"Passengers_Out\":\"Passengers\",\n",
    "        \"Freight_Out\":\"Freight_tonnes\",\n",
    "        \"Mail_Out\":\"Mail_tonnes\",\n",
    "        \"Month_num\":\"Month\"\n",
    "    })\n",
    "\n",
    "    out = pd.concat([inbound, outbound], ignore_index=True)\n",
    "\n",
    "    # Clean airline names & country strings\n",
    "    out[\"Airline_Name\"] = out[\"Airline_Name\"].astype(str).str.strip()\n",
    "    out[\"Country\"]      = out[\"Country\"].astype(str).str.strip()\n",
    "\n",
    "    # Drop rows with no airline or no direction (junk)\n",
    "    out = out.dropna(subset=[\"Airline_Name\",\"Direction\"])\n",
    "\n",
    "    # Ensure ints for Year/Month\n",
    "    out[\"Year\"]  = pd.to_numeric(out[\"Year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    out[\"Month\"] = pd.to_numeric(out[\"Month\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # Flag 'ALL SERVICES' totals if present\n",
    "    out[\"Is_Total_AllServices\"] = out[\"Country\"].str.upper().eq(\"ALL SERVICES\")\n",
    "\n",
    "    # Final sort & columns\n",
    "    return out[[\n",
    "        \"Year\",\"Month\",\"Airline_Name\",\"Country\",\"Direction\",\n",
    "        \"Passengers\",\"Freight_tonnes\",\"Mail_tonnes\",\"Is_Total_AllServices\"\n",
    "    ]].sort_values([\"Year\",\"Month\",\"Airline_Name\",\"Country\",\"Direction\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da6e9ae",
   "metadata": {},
   "source": [
    "# 3) Clean May 2025 Table 1 (per-airline country inbound/outbound PAX/Freight/Mail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac8b8dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_table1_may(df_raw: pd.DataFrame, year=2025, month=5) -> pd.DataFrame:\n",
    "    df = clean_cols(df_raw)\n",
    "    # Expected columns like:\n",
    "    # Scheduled Operator, Country to/from, Inbound_Passengers, Inbound_Freight, Inbound_Mail, Outbound_Passengers, Outbound_Freight, Outbound_Mail\n",
    "    ren = {\n",
    "        \"Scheduled_Operator\":\"Airline_Name\",\n",
    "        \"Country_to/from\":\"Country\",\n",
    "        \"Inbound_Passengers\":\"Inbound_Passengers\",\n",
    "        \"Inbound_Freight\":\"Inbound_Freight_tonnes\",\n",
    "        \"Inbound_Mail\":\"Inbound_Mail_tonnes\",\n",
    "        \"Outbound_Passengers\":\"Outbound_Passengers\",\n",
    "        \"Outbound_Freight\":\"Outbound_Freight_tonnes\",\n",
    "        \"Outbound_Mail\":\"Outbound_Mail_tonnes\",\n",
    "    }\n",
    "    df = df.rename(columns={c: ren.get(c, c) for c in df.columns})\n",
    "\n",
    "    # Numbers\n",
    "    for c in [\"Inbound_Passengers\",\"Outbound_Passengers\",\n",
    "              \"Inbound_Freight_tonnes\",\"Outbound_Freight_tonnes\",\n",
    "              \"Inbound_Mail_tonnes\",\"Outbound_Mail_tonnes\"]:\n",
    "        if c in df: df[c] = to_number(df[c])\n",
    "\n",
    "    # Build long form (two rows per operator-country: inbound/outbound)\n",
    "    keep = [\"Airline_Name\",\"Country\"]\n",
    "    inbound = df[keep + [\"Inbound_Passengers\",\"Inbound_Freight_tonnes\",\"Inbound_Mail_tonnes\"]].copy()\n",
    "    inbound[\"Direction\"] = \"Inbound\"\n",
    "    inbound = inbound.rename(columns={\n",
    "        \"Inbound_Passengers\":\"Passengers\",\n",
    "        \"Inbound_Freight_tonnes\":\"Freight_tonnes\",\n",
    "        \"Inbound_Mail_tonnes\":\"Mail_tonnes\"\n",
    "    })\n",
    "\n",
    "    outbound = df[keep + [\"Outbound_Passengers\",\"Outbound_Freight_tonnes\",\"Outbound_Mail_tonnes\"]].copy()\n",
    "    outbound[\"Direction\"] = \"Outbound\"\n",
    "    outbound = outbound.rename(columns={\n",
    "        \"Outbound_Passengers\":\"Passengers\",\n",
    "        \"Outbound_Freight_tonnes\":\"Freight_tonnes\",\n",
    "        \"Outbound_Mail_tonnes\":\"Mail_tonnes\"\n",
    "    })\n",
    "\n",
    "    out = pd.concat([inbound, outbound], ignore_index=True)\n",
    "    out[\"Year\"]  = year\n",
    "    out[\"Month\"] = month\n",
    "    out[\"Is_Total_AllServices\"] = out[\"Country\"].str.upper().eq(\"ALL SERVICES\")\n",
    "\n",
    "    return out[[\n",
    "        \"Year\",\"Month\",\"Airline_Name\",\"Country\",\"Direction\",\n",
    "        \"Passengers\",\"Freight_tonnes\",\"Mail_tonnes\",\"Is_Total_AllServices\"\n",
    "    ]].sort_values([\"Airline_Name\",\"Country\",\"Direction\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892f3b3e",
   "metadata": {},
   "source": [
    "# 4) Clean May 2025 Table 2 (market share & YoY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46f751a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_table2_may(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = clean_cols(df_raw)\n",
    "    # Examples: Scheduled Operators, Country to/from, Total Passengers_2024, Total Passengers_2025, Total Passengers_Perc_TOTAL, Total Passengers_Perc_Change\n",
    "    ren = {\n",
    "        \"Scheduled_Operators\":\"Airline_Name\",\n",
    "        \"Country_to/from\":\"Country\",\n",
    "        \"Total_Passengers_2024\":\"Passengers_May_LY\",\n",
    "        \"Total_Passengers_2025\":\"Passengers_May\",\n",
    "        \"Total_Passengers_Perc_TOTAL\":\"MarketShare_Passengers\",\n",
    "        \"Total_Passengers_Perc_Change\":\"Passengers_YoY\",\n",
    "        \"Total_Freight_tonnes_2024\":\"Freight_2024_t\",\n",
    "        \"Total_Freight_tonnes_2025\":\"Freight_2025_t\",\n",
    "        \"Total_Freight_tonnes_Perc_TOTAL\":\"MarketShare_Freight\",\n",
    "        \"Total_Freight_tonnes_Perc_Change\":\"Freight_YoY\",\n",
    "        \"Total_Mail_tonnes_2024\":\"Mail_2024_t\",\n",
    "        \"Total_Mail_tonnes_2025\":\"Mail_2025_t\",\n",
    "        \"Total_Mail_tonnes_Perc_TOTAL\":\"MarketShare_Mail\",\n",
    "        \"Total_Mail_tonnes_Perc_Change\":\"Mail_YoY\",\n",
    "    }\n",
    "    df = df.rename(columns={c: ren.get(c, c) for c in df.columns})\n",
    "\n",
    "    # Numbers\n",
    "    for c in [\"Passengers_May_LY\",\"Passengers_May\",\"Freight_2024_t\",\"Freight_2025_t\",\"Mail_2024_t\",\"Mail_2025_t\"]:\n",
    "        if c in df: df[c] = to_number(df[c])\n",
    "\n",
    "    for c in [\"MarketShare_Passengers\",\"Passengers_YoY\",\"MarketShare_Freight\",\"Freight_YoY\",\"MarketShare_Mail\",\"Mail_YoY\"]:\n",
    "        if c in df: df[c] = to_percent_decimal(df[c])\n",
    "\n",
    "    return df.sort_values([\"Airline_Name\",\"Country\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c40aed4",
   "metadata": {},
   "source": [
    "# 5) Clean May 2025 Table 3 (flights, seats, utilisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8e8075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_table3_may(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = clean_cols(df_raw)\n",
    "    ren = {\n",
    "        \"Scheduled_Operator\":\"Airline_Name\",\n",
    "        \"Service_to/from\":\"Service_Region\",\n",
    "        \"Inbound_No._of_Flights\":\"Inbound_Flights\",\n",
    "        \"Inbound_Pax_Carried\":\"Inbound_Passengers\",\n",
    "        \"Inbound_Seats_Available\":\"Inbound_Seats_Available\",\n",
    "        \"Inbound_Seat_Utilisation_%\":\"Inbound_Seat_Utilisation\",\n",
    "        \"Outbound_No._of_Flights\":\"Outbound_Flights\",\n",
    "        \"Outbound_Pax_Carried\":\"Outbound_Passengers\",\n",
    "        \"Outbound_Seats_Available\":\"Outbound_Seats_Available\",\n",
    "        \"Outbound_Seat_Utilisation_%\":\"Outbound_Seat_Utilisation\",\n",
    "    }\n",
    "    df = df.rename(columns={c: ren.get(c, c) for c in df.columns})\n",
    "\n",
    "    nums = [\"Inbound_Flights\",\"Inbound_Passengers\",\"Inbound_Seats_Available\",\n",
    "            \"Outbound_Flights\",\"Outbound_Passengers\",\"Outbound_Seats_Available\"]\n",
    "    for c in nums:\n",
    "        if c in df: df[c] = to_number(df[c])\n",
    "\n",
    "    for c in [\"Inbound_Seat_Utilisation\",\"Outbound_Seat_Utilisation\"]:\n",
    "        if c in df: df[c] = to_percent_decimal(df[c])\n",
    "\n",
    "    # Long two directions\n",
    "    keep = [\"Airline_Name\",\"Service_Region\"]\n",
    "    inbound = df[keep + [\"Inbound_Flights\",\"Inbound_Passengers\",\"Inbound_Seats_Available\",\"Inbound_Seat_Utilisation\"]].copy()\n",
    "    inbound[\"Direction\"] = \"Inbound\"\n",
    "    inbound = inbound.rename(columns={\n",
    "        \"Inbound_Flights\":\"Flights\",\n",
    "        \"Inbound_Passengers\":\"Passengers\",\n",
    "        \"Inbound_Seats_Available\":\"Seats_Available\",\n",
    "        \"Inbound_Seat_Utilisation\":\"Seat_Utilisation\"\n",
    "    })\n",
    "\n",
    "    outbound = df[keep + [\"Outbound_Flights\",\"Outbound_Passengers\",\"Outbound_Seats_Available\",\"Outbound_Seat_Utilisation\"]].copy()\n",
    "    outbound[\"Direction\"] = \"Outbound\"\n",
    "    outbound = outbound.rename(columns={\n",
    "        \"Outbound_Flights\":\"Flights\",\n",
    "        \"Outbound_Passengers\":\"Passengers\",\n",
    "        \"Outbound_Seats_Available\":\"Seats_Available\",\n",
    "        \"Outbound_Seat_Utilisation\":\"Seat_Utilisation\"\n",
    "    })\n",
    "\n",
    "    out = pd.concat([inbound, outbound], ignore_index=True)\n",
    "    out[\"Year\"] = 2025\n",
    "    out[\"Month\"] = 5\n",
    "\n",
    "    return out[[\"Year\",\"Month\",\"Airline_Name\",\"Service_Region\",\"Direction\",\n",
    "                \"Flights\",\"Passengers\",\"Seats_Available\",\"Seat_Utilisation\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baa3d98",
   "metadata": {},
   "source": [
    "# 6) Clean May 2025 Table 4 (airport totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bb65097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_table4_may(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = clean_cols(df_raw)\n",
    "    # City, Indicator, Inbound_2024, Inbound_2025, Inbound_Perc_Change, Outbound_2024, Outbound_2025, Outbound_Perc_Change\n",
    "    for c in [c for c in df.columns if re.search(r\"(Inbound|Outbound)_\\d{4}$\", c)]:\n",
    "        df[c] = to_number(df[c])\n",
    "    for c in [c for c in df.columns if c.endswith(\"_Perc_Change\")]:\n",
    "        df[c] = to_percent_decimal(df[c])\n",
    "\n",
    "    # Long by direction & metric\n",
    "    def melt_dir(prefix):\n",
    "        cols = [c for c in df.columns if c.startswith(prefix)]\n",
    "        out = pd.DataFrame({\n",
    "            \"City\": df[\"City\"],\n",
    "            \"Metric\": df[\"Indicator\"].str.replace(\" \", \"_\", regex=False),\n",
    "            \"Direction\": \"Inbound\" if prefix==\"Inbound\" else \"Outbound\",\n",
    "            \"Year_2024\": df[f\"{prefix}_2024\"],\n",
    "            \"Year_2025\": df[f\"{prefix}_2025\"],\n",
    "            \"YoY\": df[f\"{prefix}_Perc_Change\"],\n",
    "        })\n",
    "        return out\n",
    "\n",
    "    inbound  = melt_dir(\"Inbound\")\n",
    "    outbound = melt_dir(\"Outbound\")\n",
    "    long = pd.concat([inbound, outbound], ignore_index=True)\n",
    "    # Create long rows for each Year separately (useful for Power BI)\n",
    "    y24 = long[[\"City\",\"Metric\",\"Direction\",\"Year_2024\"]].rename(columns={\"Year_2024\":\"Value\"}); y24[\"Year\"] = 2024\n",
    "    y25 = long[[\"City\",\"Metric\",\"Direction\",\"Year_2025\"]].rename(columns={\"Year_2025\":\"Value\"}); y25[\"Year\"] = 2025\n",
    "    out = pd.concat([y24, y25], ignore_index=True)\n",
    "    return out[[\"Year\",\"City\",\"Metric\",\"Direction\",\"Value\"]].sort_values([\"City\",\"Metric\",\"Direction\",\"Year\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74753d9",
   "metadata": {},
   "source": [
    "# 7) Clean May 2025 Table 5 (city pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fda94a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_table5_may(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = clean_cols(df_raw)\n",
    "    # Foreign_Port, Australian_Port, Passengers_2024_Inbound, Passengers_2024_Outbound, ... , Freight (tonnes)_2025_Inbound ...\n",
    "    # Keep only PAX (focus), but keep freight if you want later.\n",
    "    def pull(year, direction):\n",
    "        c = f\"Passengers_{year}_{direction}\"\n",
    "        if c in df: return to_number(df[c])\n",
    "        return pd.Series([None]*len(df))\n",
    "\n",
    "    out_rows = []\n",
    "    for yr in (2024, 2025):\n",
    "        for d in (\"Inbound\",\"Outbound\"):\n",
    "            tmp = pd.DataFrame({\n",
    "                \"Year\": yr,\n",
    "                \"Australian_City\": df[\"Australian_Port\"],\n",
    "                \"Foreign_City\": df[\"Foreign_Port\"],\n",
    "                \"Direction\": d,\n",
    "                \"Metric\": \"Passengers\",\n",
    "                \"Value\": pull(yr, d)\n",
    "            })\n",
    "            out_rows.append(tmp)\n",
    "    out = pd.concat(out_rows, ignore_index=True)\n",
    "\n",
    "    # Drop \"Total, Broome\"–like summary rows if present\n",
    "    bad = out[\"Australian_City\"].astype(str).str.lower().str.startswith(\"total\")\n",
    "    out = out[~bad].reset_index(drop=True)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a35f4fa",
   "metadata": {},
   "source": [
    "# 8) RUN CLEANING PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f650d06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ fact_airline_monthly_hist: (41664, 9)\n",
      "✅ Table1_May2025_clean: (270, 9)\n",
      "✅ Table2_May2025_clean: (144, 14)\n",
      "✅ Table3_May2025_clean: (244, 9)\n",
      "✅ Table4_Cities_long: (144, 5)\n",
      "✅ Table5_pairs_long: (1028, 6)\n"
     ]
    }
   ],
   "source": [
    "hist_raw = pd.read_csv(FILES[\"hist_t1\"], dtype=str)\n",
    "t1_hist  = clean_table1_hist(hist_raw)\n",
    "t1_hist.to_csv(CLEAN / \"fact_airline_monthly_hist.csv\", index=False)\n",
    "print(\"✅ fact_airline_monthly_hist:\", t1_hist.shape)\n",
    "\n",
    "t1_may_raw = pd.read_csv(FILES[\"t1_may\"], dtype=str)\n",
    "t1_may = clean_table1_may(t1_may_raw, year=2025, month=5)\n",
    "t1_may.to_csv(CLEAN / \"Table1_May2025_clean.csv\", index=False)\n",
    "print(\"✅ Table1_May2025_clean:\", t1_may.shape)\n",
    "\n",
    "t2_may_raw = pd.read_csv(FILES[\"t2_may\"], dtype=str)\n",
    "t2_may = clean_table2_may(t2_may_raw)\n",
    "t2_may.to_csv(CLEAN / \"Table2_May2025_clean.csv\", index=False)\n",
    "print(\"✅ Table2_May2025_clean:\", t2_may.shape)\n",
    "\n",
    "t3_may_raw = pd.read_csv(FILES[\"t3_may\"], dtype=str)\n",
    "t3_may = clean_table3_may(t3_may_raw)\n",
    "t3_may.to_csv(CLEAN / \"Table3_May2025_clean.csv\", index=False)\n",
    "print(\"✅ Table3_May2025_clean:\", t3_may.shape)\n",
    "\n",
    "t4_may_raw = pd.read_csv(FILES[\"t4_may\"], dtype=str)\n",
    "t4_long = clean_table4_may(t4_may_raw)\n",
    "t4_long.to_csv(CLEAN / \"Table4_Cities_long.csv\", index=False)\n",
    "print(\"✅ Table4_Cities_long:\", t4_long.shape)\n",
    "\n",
    "t5_may_raw = pd.read_csv(FILES[\"t5_may\"], dtype=str)\n",
    "t5_long = clean_table5_may(t5_may_raw)\n",
    "t5_long.to_csv(CLEAN / \"Table5_pairs_long.csv\", index=False)\n",
    "print(\"✅ Table5_pairs_long:\", t5_long.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac40f0de",
   "metadata": {},
   "source": [
    "# 9) QUICK SANITY CHECKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8d67cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SANITY: Historical ---\n",
      "🔎 NA check [fact_airline_monthly_hist]: {'Year': 0, 'Month': 0, 'Airline_Name': 0, 'Direction': 0, 'Passengers': 7859}\n",
      "🔎 Range [fact_airline_monthly_hist.Passengers]: min=0.0  max=187429.0\n",
      "\n",
      "--- SANITY: May T1 ---\n",
      "🔎 NA check [Table1_May2025_clean]: {'Year': 0, 'Month': 0, 'Airline_Name': 0, 'Country': 0, 'Direction': 0, 'Passengers': 36}\n",
      "🔎 Range [Table1_May2025_clean.Passengers]: min=214.0  max=286281.0\n",
      "\n",
      "--- SANITY: May T2 ---\n",
      "🔎 NA check [Table2_May2025_clean]: {'Airline_Name': 0, 'Passengers_May': 27, 'Passengers_YoY': 28, 'MarketShare_Passengers': 27}\n",
      "\n",
      "--- SANITY: May T3 ---\n",
      "🔎 NA check [Table3_May2025_clean]: {'Year': 0, 'Month': 0, 'Airline_Name': 0, 'Service_Region': 0, 'Direction': 0, 'Flights': 7, 'Passengers': 28}\n",
      "\n",
      "--- SANITY: May T4 ---\n",
      "🔎 NA check [Table4_Cities_long]: {'Year': 0, 'City': 0, 'Metric': 0, 'Direction': 0, 'Value': 21}\n",
      "\n",
      "--- SANITY: May T5 ---\n",
      "🔎 NA check [Table5_pairs_long]: {'Year': 0, 'Australian_City': 0, 'Foreign_City': 0, 'Direction': 0, 'Metric': 0, 'Value': 0}\n",
      "\n",
      "✅ Done. Clean CSVs written to: /Users/kevantamom/Desktop/GITHUB/aviation-insights/data/clean\n"
     ]
    }
   ],
   "source": [
    "def check_not_null(df, cols, name):\n",
    "    missing = {c: df[c].isna().sum() for c in cols if c in df}\n",
    "    print(f\"🔎 NA check [{name}]:\", missing)\n",
    "\n",
    "def check_ranges(df, col, name):\n",
    "    if col in df:\n",
    "        print(f\"🔎 Range [{name}.{col}]: min={pd.to_numeric(df[col], errors='coerce').min()}  max={pd.to_numeric(df[col], errors='coerce').max()}\")\n",
    "\n",
    "print(\"\\n--- SANITY: Historical ---\")\n",
    "check_not_null(t1_hist, [\"Year\",\"Month\",\"Airline_Name\",\"Direction\",\"Passengers\"], \"fact_airline_monthly_hist\")\n",
    "check_ranges(t1_hist, \"Passengers\", \"fact_airline_monthly_hist\")\n",
    "\n",
    "print(\"\\n--- SANITY: May T1 ---\")\n",
    "check_not_null(t1_may, [\"Year\",\"Month\",\"Airline_Name\",\"Country\",\"Direction\",\"Passengers\"], \"Table1_May2025_clean\")\n",
    "check_ranges(t1_may, \"Passengers\", \"Table1_May2025_clean\")\n",
    "\n",
    "print(\"\\n--- SANITY: May T2 ---\")\n",
    "check_not_null(t2_may, [\"Airline_Name\",\"Passengers_May\",\"Passengers_YoY\",\"MarketShare_Passengers\"], \"Table2_May2025_clean\")\n",
    "\n",
    "print(\"\\n--- SANITY: May T3 ---\")\n",
    "check_not_null(t3_may, [\"Year\",\"Month\",\"Airline_Name\",\"Service_Region\",\"Direction\",\"Flights\",\"Passengers\"], \"Table3_May2025_clean\")\n",
    "\n",
    "print(\"\\n--- SANITY: May T4 ---\")\n",
    "check_not_null(t4_long, [\"Year\",\"City\",\"Metric\",\"Direction\",\"Value\"], \"Table4_Cities_long\")\n",
    "\n",
    "print(\"\\n--- SANITY: May T5 ---\")\n",
    "check_not_null(t5_long, [\"Year\",\"Australian_City\",\"Foreign_City\",\"Direction\",\"Metric\",\"Value\"], \"Table5_pairs_long\")\n",
    "\n",
    "print(\"\\n✅ Done. Clean CSVs written to:\", CLEAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4724622",
   "metadata": {},
   "source": [
    "# Finalisation/ Renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e679323b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ fact_airline_country_monthly_hist: (33805, 9)\n",
      "✅ fact_airline_country_monthly_may2025: (234, 9)\n",
      "✅ fact_airline_marketshare_monthly_may2025: (144, 14)\n",
      "✅ fact_airline_region_ops_monthly_may2025: (237, 9)\n",
      "✅ fact_airport_totals_monthly_may2025: (123, 5)\n",
      "✅ fact_citypair_monthly_may2025: (1028, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "CLEAN = Path(\"../data/clean\")\n",
    "PBI   = Path(\"../data/powerbi\")\n",
    "PBI.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Load cleaned intermediates ---\n",
    "t1_hist  = pd.read_csv(CLEAN / \"fact_airline_monthly_hist.csv\")\n",
    "t1_may   = pd.read_csv(CLEAN / \"Table1_May2025_clean.csv\")\n",
    "t2_may   = pd.read_csv(CLEAN / \"Table2_May2025_clean.csv\")\n",
    "t3_may   = pd.read_csv(CLEAN / \"Table3_May2025_clean.csv\")\n",
    "t4_long  = pd.read_csv(CLEAN / \"Table4_Cities_long.csv\")\n",
    "t5_long  = pd.read_csv(CLEAN / \"Table5_pairs_long.csv\")\n",
    "\n",
    "# ---------- Passenger-focused “final” slices ----------\n",
    "# Historical passenger fact\n",
    "fact_airline_country_monthly_hist = t1_hist.loc[~t1_hist[\"Passengers\"].isna()].copy()\n",
    "fact_airline_country_monthly_hist.to_csv(PBI / \"fact_airline_country_monthly_hist.csv\", index=False)\n",
    "\n",
    "# May Table 1 passenger slice\n",
    "fact_airline_country_monthly_may2025 = t1_may.loc[~t1_may[\"Passengers\"].isna()].copy()\n",
    "fact_airline_country_monthly_may2025.to_csv(PBI / \"fact_airline_country_monthly_may2025.csv\", index=False)\n",
    "\n",
    "# May Table 2 (with fill0 for dashboards if needed)\n",
    "t2_fill0 = t2_may.copy()\n",
    "for c in [\"Passengers_May\",\"Passengers_May_LY\",\"MarketShare_Passengers\",\"Passengers_YoY\"]:\n",
    "    if c in t2_fill0: \n",
    "        t2_fill0[c] = t2_fill0[c].fillna(0)\n",
    "t2_fill0.to_csv(PBI / \"fact_airline_marketshare_monthly_may2025.csv\", index=False)\n",
    "\n",
    "# May Table 3 (ops: flights, seats, passengers by region)\n",
    "fact_airline_region_ops_monthly_may2025 = t3_may.loc[~t3_may[\"Flights\"].isna()].copy()\n",
    "fact_airline_region_ops_monthly_may2025.to_csv(PBI / \"fact_airline_region_ops_monthly_may2025.csv\", index=False)\n",
    "\n",
    "# May Table 4 (airport totals)\n",
    "fact_airport_totals_monthly_may2025 = t4_long.loc[~t4_long[\"Value\"].isna()].copy()\n",
    "fact_airport_totals_monthly_may2025.to_csv(PBI / \"fact_airport_totals_monthly_may2025.csv\", index=False)\n",
    "\n",
    "# May Table 5 (city pairs, already clean)\n",
    "fact_citypair_monthly_may2025 = t5_long.copy()\n",
    "fact_citypair_monthly_may2025.to_csv(PBI / \"fact_citypair_monthly_may2025.csv\", index=False)\n",
    "\n",
    "# -------- Confirmation --------\n",
    "print(\"✅ fact_airline_country_monthly_hist:\", fact_airline_country_monthly_hist.shape)\n",
    "print(\"✅ fact_airline_country_monthly_may2025:\", fact_airline_country_monthly_may2025.shape)\n",
    "print(\"✅ fact_airline_marketshare_monthly_may2025:\", t2_fill0.shape)\n",
    "print(\"✅ fact_airline_region_ops_monthly_may2025:\", fact_airline_region_ops_monthly_may2025.shape)\n",
    "print(\"✅ fact_airport_totals_monthly_may2025:\", fact_airport_totals_monthly_may2025.shape)\n",
    "print(\"✅ fact_citypair_monthly_may2025:\", fact_citypair_monthly_may2025.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1e324a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
